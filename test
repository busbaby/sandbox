import argparse
import os
import sys
import cv2
import re
import time
import torch

class VideoStream:
    def __init__(self, videoFile):
        self.cap = cv2.VideoCapture(videoFile)

    def getFrames(self, count):
        frames = []
        if self.cap.isOpened():
            while count > 0:
                success, frame = self.cap.read()
                if not success:
                    self.cap.release()
                    break
                frames.append(frame)
                count -= 1
        return frames

model = torch.hub.load('ultralytics/yolov5', 'yolov5s')
model.classes = 0

def getCrowdDensity(frame):
    # may want to resize and grayscale frame to speed up detection
    detections = model(frame)
    rs = detections.pandas().xyxy[0]
    print(rs)
    personCount = 0
    personDensity = 0
    for index, row in rs.iterrows():
        if row["class"] == 0:
                personDensity += ((row["xmax"] - row["xmin"]) * (row["ymax"] - row["ymin"])) * row["confidence"]
                personCount += 1
    return personDensity * personCount

parser = argparse.ArgumentParser()
parser.add_argument('--source', action='append', help='Video source directory/file', required=True)
args = parser.parse_args()

videoStreams = []
for s in args.source:
    s = os.path.abspath(s)
    if not os.path.exists(s):
        print(f"No such file: {s}", file=sys.stderr)
        exit(1)
    elif not re.match('.*.mp4$', s, re.IGNORECASE):
        print(f"Unsupported file extension: {s}", file=sys.stderr)
        exit(1)
    videoStreams.append(VideoStream(s))

st = time.time()
FPS = 30
CHUNKSIZE = FPS * 2 # Read in 2 second chunks

while True:
    chunks = []
    maxDensity = -1
    maxDensityIndex = -1
    for index in range(len(videoStreams)):
        frames = videoStreams[index].getFrames(CHUNKSIZE)
        if len(frames) == CHUNKSIZE:
            chunks.append(frames)
            density = getCrowdDensity(frames[0])
            if density > maxDensity:
                maxDensity = density
                maxDensityIndex = index
            
    if len(chunks) == 0:
        break
    focusedFrames = chunks.pop[maxDensityIndex]
    # Write focused frames to output video here
    # Overlay all audio channels from framesSet


elapsed_time = time.time() - st
print('Execution time:', elapsed_time, 'seconds')